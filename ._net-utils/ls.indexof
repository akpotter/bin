#!/bin/sh
# List the content of `index of` html pages (generated by servers when no index file present), files only, sorted by name.
#   Usage: ls.indexof <url...>
#     e.g. ls.indexof https://dumps.wikimedia.org/enwiki/latest/ https://dumps.wikimedia.org/ruwiki/latest/ 
output_piped() { test -t 1; }

for baseurl in "$@"
do
  curl -s "$baseurl" \
    | grep '<a href="[^./]' \
    | sed -E 's/<a href="([^"]*)">.*?<\/a>/\1\t/g; s/\s{2,}/\t/g; s/\r//g' \
    | awk -F'\t+' '$3 ~ /^[0-9]+$/' \
    | numfmt --field=3 --delimiter=$'\t' --to=iec --suffix=B --padding=8 \
    | sort \
    | (if output_piped; then align; else cat; fi)
done
